Este projeto √© uma plataforma SaaS para monitoramento de reservas a√©reas (GOL, LATAM, AZUL) e status de voos em tempo real. O sistema utiliza uma arquitetura baseada em eventos para processar raspagem de dados (scraping) de forma ass√≠ncrona e escal√°vel.

## üìê Arquitetura do Sistema

O projeto √© dividido em dois servi√ßos principais que se comunicam via Redis:
- **Core Application (Next.js)**: Frontend, Autentica√ß√£o, Banco de Dados e API Gateway.
- **Scraper Service (Node.js Worker)**: Servi√ßo isolado respons√°vel por executar a automa√ß√£o de navegadores.

### Fluxo de Execu√ß√£o
1. Usu√°rio adiciona um voo no Dashboard.
2. Next.js envia um Job para a fila Redis (`scrape-queue`).
3. Next.js retorna imediatamente um `jobId` para o frontend (Polling).
4. Scraper Worker pega o Job, escolhe a estrat√©gia (Direta ou Proxy) e executa o Playwright.
5. Scraper Worker salva o resultado no Redis.
6. Next.js recupera o resultado, salva no Supabase e exibe ao usu√°rio.

## üõ†Ô∏è Tech Stack

### Core (Frontend/API)
- **Framework**: Next.js 14+ (App Router)
- **Linguagem**: TypeScript
- **Database**: Supabase (PostgreSQL)
- **Auth**: Supabase Auth
- **UI**: Tailwind CSS + Shadcn/UI

### Scraper Service (Worker)
- **Runtime**: Node.js
- **Fila/Queue**: BullMQ
- **Cache/PubSub**: Redis (Upstash ou Self-hosted)
- **Browser Automation**: Playwright (Chromium) + puppeteer-extra-plugin-stealth
- **Proxy Manager**: L√≥gica customizada (Conex√£o Direta -> Fallback Proxy Residencial)

## üöÄ Como Rodar Localmente

### Pr√©-requisitos
- Node.js 18+
- Inst√¢ncia Redis rodando (Local ou Cloud)
- Conta Supabase configurada

### 1. Configura√ß√£o do Core (Next.js)

Na raiz do projeto (`/flyio`):

```bash
# Instalar depend√™ncias
npm install

# Configurar vari√°veis de ambiente
cp .env.example .env.local
```

Conte√∫do do `.env.local`:

```env
NEXT_PUBLIC_SUPABASE_URL=sua_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=sua_key
SUPABASE_SERVICE_ROLE_KEY=sua_service_key
REDIS_URL=redis://127.0.0.1:6379 # Ou sua URL do Upstash
SCRAPER_SERVICE_URL=http://127.0.0.1:8080/scrape # URL do worker local
CRON_SECRET=sua_senha_segura
```

### 2. Configura√ß√£o do Scraper Service

Entre na pasta do servi√ßo:

```bash
cd scraper-service

# Instalar depend√™ncias
npm install

# Instalar bin√°rios dos navegadores (Essencial!)
npx playwright install chromium

# Configurar vari√°veis
cp .env.example .env
```

Conte√∫do do `scraper-service/.env`:

```env
PORT=8080
ENABLE_WORKER=true
REDIS_URL=redis://127.0.0.1:6379 # Deve ser o MESMO Redis do Next.js

# Configura√ß√£o de Proxy (Webshare)
PROXY_SERVER=http://p.webshare.io:80
PROXY_PASSWORD=seu_password
TOTAL_PROXIES=250
```

### 3. Iniciando a Aplica√ß√£o

Voc√™ precisar√° de dois terminais abertos:

**Terminal 1 (Worker):**
```bash
cd scraper-service
node server.js
# Output esperado: üë∑ Iniciando Worker... üöÄ API running on port 8080
```

**Terminal 2 (Frontend):**
```bash
# Na raiz do projeto
npm run dev
# Output: Ready on http://localhost:3000
```

## üß† L√≥gica de Scraping (Detalhes T√©cnicos)

O arquivo `scraper.js` implementa estrat√©gias avan√ßadas para evitar bloqueios:

### Estrat√©gia de Rede
- **Tentativa 1 (Conex√£o Direta)**: O rob√¥ tenta acessar o site da cia a√©rea sem proxy para m√°xima velocidade.
- **Tentativa 2 (Fallback Proxy)**: Se houver bloqueio ou erro de rede, ele reinicia o navegador usando um proxy residencial rotativo.

### Tratamento por Companhia

#### GOL:
- Usa emula√ß√£o de Desktop Full HD.
- Simula digita√ß√£o humana lenta (delay: 400ms).
- Navega√ß√£o por teclado (Tab + Tab + Enter) para selecionar aeroportos, evitando falhas em Web Components.
- **Persist√™ncia de Sess√£o**: Salva cookies (`session_gol.json`) ap√≥s o sucesso para reutilizar em execu√ß√µes futuras e diminuir o "Trust Score" de bot.
- **Anti-Popup**: Loop que detecta e fecha modais de erro ("Houve um erro") tentando buscar novamente at√© 3 vezes.

#### LATAM:
- Extra√ß√£o robusta do JSON da API interna (`itineraryParts`).
- Normaliza√ß√£o do `flightNumber` para evitar erros de banco (ex: duplicidade `LALA3000`).
- **Fallback H√≠brido**: Se a API falhar, tenta ler o n√∫mero do voo diretamente do HTML da p√°gina.

#### AZUL:
- Intercepta√ß√£o direta da API de `journeys`.

## üì¶ Deploy (Google Cloud Run)

Este projeto est√° configurado para deploy via Dockerfile no Cloud Run.

### Dockerfile do Scraper
O Worker usa uma imagem base do Playwright para garantir que todas as depend√™ncias do sistema operacional (linux libs) estejam presentes.

`Dockerfile`
```dockerfile
FROM mcr.microsoft.com/playwright:v1.48.0-focal
WORKDIR /app
COPY package.json ./
RUN npm install
# Instala apenas o necess√°rio
RUN npx playwright install --with-deps chromium
COPY . .
EXPOSE 8080
CMD [ "node", "server.js" ]
```

## ‚ö†Ô∏è Troubleshooting Comum

- **Erro ECONNREFUSED no Next.js**:
  O `scraper-service` n√£o est√° rodando ou a vari√°vel `SCRAPER_SERVICE_URL` est√° errada.

- **Erro Job not found (404)**:
  O Redis pode estar limpando os jobs muito r√°pido. Verifique a configura√ß√£o `removeOnComplete` no `queue.js`.

- **Playwright erro Executable not found**:
  Voc√™ esqueceu de rodar `npx playwright install` no ambiente onde o node est√° rodando.

- **Banco de dados null constraint**:
  A extra√ß√£o falhou. Verifique os logs do Worker para ver se o JSON da companhia a√©rea mudou a estrutura.